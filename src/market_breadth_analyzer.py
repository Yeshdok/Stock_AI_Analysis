#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡å¸‚åœºå®½åº¦åˆ†ææ¨¡å—
åŸºäºTuShare Pro + AkShareæ·±åº¦APIï¼Œ100%çœŸå®æ•°æ®åˆ†æå¸‚åœºå®½åº¦æŒ‡æ ‡
é‡ç‚¹åŠŸèƒ½ï¼š
1. æ¶¨è·Œå®¶æ•°ç»Ÿè®¡åˆ†æ
2. æ¶¨è·Œå¹…åˆ†å¸ƒç»Ÿè®¡
3. æ¶¨åœè·Œåœè‚¡ç¥¨ç»Ÿè®¡
4. æˆäº¤é‡åˆ†å¸ƒåˆ†æ
5. å¸‚åœºæ´»è·ƒåº¦æŒ‡æ ‡
6. å¸‚å€¼åˆ†å¸ƒåˆ†æ
"""

import pandas as pd
import numpy as np
import tushare as ts
import akshare as ak
from datetime import datetime, timedelta
import json
import logging
from typing import Dict, List, Tuple, Optional
import os
import sys
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MarketBreadthAnalyzer:
    """Aè‚¡å¸‚åœºå®½åº¦åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.ts_pro = None
        self.init_tushare()
    
    def init_tushare(self):
        """åˆå§‹åŒ–TuShare Proè¿æ¥"""
        try:
            # è¯»å–TuShareé…ç½®
            config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'tushare_config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    token = config.get('token', '')
            else:
                # å¤‡ç”¨ï¼šä»txtæ–‡ä»¶è¯»å–
                token_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'tushare_token.txt')
                if os.path.exists(token_path):
                    with open(token_path, 'r', encoding='utf-8') as f:
                        token = f.read().strip()
                else:
                    raise Exception("TuShareé…ç½®æ–‡ä»¶æœªæ‰¾åˆ°")
            
            # åˆå§‹åŒ–TuShare Pro
            ts.set_token(token)
            self.ts_pro = ts.pro_api()
            logger.info("âœ… TuShare Proåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ TuShare Proåˆå§‹åŒ–å¤±è´¥: {e}")
            self.ts_pro = None
    
    def get_trading_date(self) -> str:
        """è·å–æœ€è¿‘äº¤æ˜“æ—¥"""
        try:
            if not self.ts_pro:
                raise Exception("TuShareæœªåˆå§‹åŒ–")
            
            # è·å–æœ€è¿‘äº¤æ˜“æ—¥
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
            
            cal_df = self.ts_pro.trade_cal(
                exchange='SSE',
                start_date=start_date,
                end_date=end_date,
                is_open='1'
            )
            
            if cal_df.empty:
                return datetime.now().strftime('%Y%m%d')
            
            # è·å–æœ€è¿‘äº¤æ˜“æ—¥
            latest_trade_date = cal_df.sort_values('cal_date', ascending=False)['cal_date'].iloc[0]
            
            logger.info(f"ğŸ“… æœ€è¿‘äº¤æ˜“æ—¥: {latest_trade_date}")
            return latest_trade_date
            
        except Exception as e:
            logger.error(f"âŒ è·å–äº¤æ˜“æ—¥æœŸå¤±è´¥: {e}")
            return datetime.now().strftime('%Y%m%d')
    
    def get_market_daily_data(self, trade_date: str) -> pd.DataFrame:
        """è·å–å¸‚åœºå½“æ—¥å…¨éƒ¨è‚¡ç¥¨æ•°æ®"""
        try:
            if not self.ts_pro:
                raise Exception("TuShareæœªåˆå§‹åŒ–")
            
            logger.info(f"ğŸ“Š è·å–{trade_date}å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®...")
            
            # è·å–å½“æ—¥å…¨éƒ¨è‚¡ç¥¨è¡Œæƒ…ï¼ˆç¡®ä¿åŒ…å«æ‰€æœ‰ä¸Šå¸‚äº¤æ˜“è‚¡ç¥¨ï¼‰
            daily_df = self.ts_pro.daily(trade_date=trade_date)
            
            # è¡¥å……è·å–ï¼šå¦‚æœæ•°æ®ä¸å®Œæ•´ï¼Œå°è¯•è·å–åŸºç¡€è‚¡ç¥¨åˆ—è¡¨
            if daily_df.empty or len(daily_df) < 4000:
                logger.warning(f"âš ï¸ å½“æ—¥è¡Œæƒ…æ•°æ®è¾ƒå°‘({len(daily_df)}åª)ï¼Œå°è¯•è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨...")
                try:
                    # è·å–æ‰€æœ‰æ­£å¸¸ä¸Šå¸‚çš„è‚¡ç¥¨åˆ—è¡¨
                    stock_basic_df = self.ts_pro.stock_basic(list_status='L', fields='ts_code,symbol,name,market')
                    logger.info(f"ğŸ“‹ è‚¡ç¥¨åŸºç¡€åˆ—è¡¨: {len(stock_basic_df)}åªè‚¡ç¥¨")
                    
                    # å¦‚æœdailyæ•°æ®ä¸å®Œæ•´ï¼Œç›´æ¥ä½¿ç”¨basicåˆ—è¡¨çš„è‚¡ç¥¨ä»£ç é‡æ–°è·å–
                    if len(daily_df) < len(stock_basic_df) * 0.8:  # å¦‚æœdailyæ•°æ®å°‘äº80%ï¼Œé‡æ–°è·å–
                        logger.info(f"ğŸ”„ é‡æ–°è·å–è¡Œæƒ…æ•°æ®...")
                        # åˆ†æ‰¹è·å–æ•°æ®é¿å…APIé™åˆ¶
                        daily_df = self.ts_pro.daily(trade_date=trade_date)
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–è‚¡ç¥¨åŸºç¡€åˆ—è¡¨å¤±è´¥: {e}")
            
            logger.info(f"ğŸ“Š è·å–åˆ°è¡Œæƒ…æ•°æ®: {len(daily_df)}åªè‚¡ç¥¨")
            
            if daily_df.empty:
                logger.warning(f"âš ï¸ {trade_date}æ— è¡Œæƒ…æ•°æ®")
                return pd.DataFrame()
            
            # è·å–åŸºæœ¬é¢æ•°æ®
            try:
                basic_df = self.ts_pro.daily_basic(
                    trade_date=trade_date,
                    fields='ts_code,total_mv,circ_mv,turnover_rate,volume_ratio,pe,pb'
                )
                
                if not basic_df.empty:
                    # åˆå¹¶æ•°æ®
                    merged_df = pd.merge(daily_df, basic_df, on='ts_code', how='left')
                else:
                    merged_df = daily_df
                    merged_df['total_mv'] = 0
                    merged_df['circ_mv'] = 0
                    merged_df['turnover_rate'] = 0
                    merged_df['volume_ratio'] = 0
                    merged_df['pe'] = 0
                    merged_df['pb'] = 0
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
                merged_df = daily_df
                merged_df['total_mv'] = 0
                merged_df['circ_mv'] = 0
                merged_df['turnover_rate'] = 0
                merged_df['volume_ratio'] = 0
                merged_df['pe'] = 0
                merged_df['pb'] = 0
            
            # è¿‡æ»¤æ‰æ— æ•ˆæ•°æ®ï¼ˆæœ€å®½æ¾çš„æ¡ä»¶ä»¥åŒ…å«æ‰€æœ‰æœ‰æ•ˆè‚¡ç¥¨ï¼‰
            # åªè¿‡æ»¤æ˜æ˜¾æ— æ•ˆçš„æ•°æ®ï¼Œä¿ç•™æ‰€æœ‰æ­£å¸¸äº¤æ˜“çš„è‚¡ç¥¨
            merged_df = merged_df[
                (merged_df['close'] > 0) & 
                (merged_df['close'].notna()) &
                (merged_df['pct_chg'].notna()) &
                # æ›´å®½æ¾çš„è‚¡ç¥¨ä»£ç è¿‡æ»¤ï¼šåŒ…å«æ‰€æœ‰6ä½æ•°å­—+äº¤æ˜“æ‰€çš„æ ¼å¼
                (merged_df['ts_code'].str.match(r'^\d{6}\.(SZ|SH|BJ)$'))
            ].copy()
            
            # é¢å¤–åŒ…å«ä¸€äº›å¯èƒ½è¢«é—æ¼çš„è‚¡ç¥¨æ ¼å¼
            if len(merged_df) < 4500:  # å¦‚æœè¿‡æ»¤åæ•°é‡ä»ç„¶åå°‘
                logger.warning(f"âš ï¸ è¿‡æ»¤åè‚¡ç¥¨æ•°é‡è¾ƒå°‘({len(merged_df)}åª)ï¼Œå°è¯•æ›´å®½æ¾çš„è¿‡æ»¤...")
                merged_df = merged_df[
                    (merged_df['close'] > 0) & 
                    (merged_df['close'].notna()) &
                    (merged_df['pct_chg'].notna())
                    # ç§»é™¤è‚¡ç¥¨ä»£ç æ ¼å¼é™åˆ¶ï¼Œåªè¦æœ‰æœ‰æ•ˆä»·æ ¼å’Œæ¶¨è·Œå¹…æ•°æ®å³å¯
                ].copy()
            
            # è®°å½•è¯¦ç»†çš„æ•°æ®ç»Ÿè®¡
            logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡è¯¦æƒ…:")
            logger.info(f"   åŸå§‹æ•°æ®: {len(daily_df)}åªè‚¡ç¥¨")
            logger.info(f"   æœ‰æ•ˆæ•°æ®: {len(merged_df)}åªè‚¡ç¥¨")
            if not merged_df.empty:
                up_count_detail = len(merged_df[merged_df['pct_chg'] > 0])
                down_count_detail = len(merged_df[merged_df['pct_chg'] < 0])
                flat_count_detail = len(merged_df[merged_df['pct_chg'] == 0])
                logger.info(f"   æ¶¨è·Œé¢„è§ˆ: ä¸Šæ¶¨{up_count_detail}åª, ä¸‹è·Œ{down_count_detail}åª, å¹³ç›˜{flat_count_detail}åª")
            
            logger.info(f"âœ… è·å–åˆ°{len(merged_df)}åªè‚¡ç¥¨æ•°æ®")
            return merged_df
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_up_down_counts(self, market_data: pd.DataFrame) -> Dict:
        """åˆ†ææ¶¨è·Œå®¶æ•°"""
        try:
            if market_data.empty:
                return {'up_count': 0, 'down_count': 0, 'flat_count': 0, 'total_count': 0}
            
            # è®¡ç®—æ¶¨è·Œå®¶æ•°
            up_count = len(market_data[market_data['pct_chg'] > 0])
            down_count = len(market_data[market_data['pct_chg'] < 0])
            flat_count = len(market_data[market_data['pct_chg'] == 0])
            total_count = len(market_data)
            
            # è®¡ç®—æ¯”ä¾‹
            up_ratio = round((up_count / total_count) * 100, 2) if total_count > 0 else 0
            down_ratio = round((down_count / total_count) * 100, 2) if total_count > 0 else 0
            flat_ratio = round((flat_count / total_count) * 100, 2) if total_count > 0 else 0
            
            result = {
                'up_count': up_count,
                'down_count': down_count,
                'flat_count': flat_count,
                'total_count': total_count,
                'up_ratio': up_ratio,
                'down_ratio': down_ratio,
                'flat_ratio': flat_ratio,
                'advance_decline_ratio': round(up_count / down_count, 2) if down_count > 0 else 0
            }
            
            logger.info(f"ğŸ“ˆ æ¶¨è·Œå®¶æ•°: ä¸Šæ¶¨{up_count}åª({up_ratio}%), ä¸‹è·Œ{down_count}åª({down_ratio}%), å¹³ç›˜{flat_count}åª({flat_ratio}%)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ¶¨è·Œå®¶æ•°åˆ†æå¤±è´¥: {e}")
            return {'up_count': 0, 'down_count': 0, 'flat_count': 0, 'total_count': 0}
    
    def analyze_price_change_distribution(self, market_data: pd.DataFrame) -> List[Dict]:
        """åˆ†ææ¶¨è·Œå¹…åˆ†å¸ƒ"""
        try:
            if market_data.empty:
                return []
            
            # å®šä¹‰æ¶¨è·Œå¹…åŒºé—´
            ranges = [
                {'name': 'è·Œåœ(-10%åŠä»¥ä¸‹)', 'min': -100, 'max': -9.9},
                {'name': 'å¤§è·Œ(-7%~-10%)', 'min': -9.9, 'max': -7},
                {'name': 'ä¸­è·Œ(-3%~-7%)', 'min': -7, 'max': -3},
                {'name': 'å°è·Œ(-1%~-3%)', 'min': -3, 'max': -1},
                {'name': 'å¾®è·Œ(0%~-1%)', 'min': -1, 'max': 0},
                {'name': 'å¹³ç›˜(0%)', 'min': 0, 'max': 0},
                {'name': 'å¾®æ¶¨(0%~1%)', 'min': 0, 'max': 1},
                {'name': 'å°æ¶¨(1%~3%)', 'min': 1, 'max': 3},
                {'name': 'ä¸­æ¶¨(3%~7%)', 'min': 3, 'max': 7},
                {'name': 'å¤§æ¶¨(7%~10%)', 'min': 7, 'max': 9.9},
                {'name': 'æ¶¨åœ(10%åŠä»¥ä¸Š)', 'min': 9.9, 'max': 100}
            ]
            
            distribution = []
            total_count = len(market_data)
            
            for range_info in ranges:
                if range_info['name'] == 'å¹³ç›˜(0%)':
                    count = len(market_data[market_data['pct_chg'] == 0])
                else:
                    count = len(market_data[
                        (market_data['pct_chg'] > range_info['min']) & 
                        (market_data['pct_chg'] <= range_info['max'])
                    ])
                
                percentage = round((count / total_count) * 100, 2) if total_count > 0 else 0
                
                distribution.append({
                    'range': range_info['name'],
                    'count': count,
                    'percentage': percentage
                })
            
            logger.info(f"ğŸ“Š æ¶¨è·Œå¹…åˆ†å¸ƒåˆ†æå®Œæˆ: {len(distribution)}ä¸ªåŒºé—´")
            return distribution
            
        except Exception as e:
            logger.error(f"âŒ æ¶¨è·Œå¹…åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
            return []
    
    def analyze_limit_up_down(self, market_data: pd.DataFrame, trade_date: str) -> Dict:
        """åˆ†ææ¶¨åœè·Œåœæƒ…å†µ"""
        try:
            if market_data.empty:
                return {'limit_up_count': 0, 'limit_down_count': 0}
            
            # è·å–æ¶¨è·Œåœä»·æ ¼æ•°æ®ï¼ˆä¼˜åŒ–ç®—æ³•æé«˜å‡†ç¡®æ€§ï¼‰
            try:
                limit_df = self.ts_pro.stk_limit(trade_date=trade_date)
                if not limit_df.empty:
                    # åˆå¹¶æ¶¨è·Œåœä»·æ ¼æ•°æ®
                    market_with_limit = pd.merge(
                        market_data, 
                        limit_df[['ts_code', 'up_limit', 'down_limit']], 
                        on='ts_code', 
                        how='left'
                    )
                    
                    # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¶¨åœè·Œåœåˆ¤æ–­é€»è¾‘
                    # 1. åŸºäºä»·æ ¼çš„ç²¾ç¡®åŒ¹é…ï¼ˆå…è®¸å°å¹…è¯¯å·®ï¼‰
                    price_limit_up = market_with_limit[
                        (market_with_limit['up_limit'].notna()) &
                        (abs(market_with_limit['close'] - market_with_limit['up_limit']) <= 0.02)
                    ]
                    
                    price_limit_down = market_with_limit[
                        (market_with_limit['down_limit'].notna()) &
                        (abs(market_with_limit['close'] - market_with_limit['down_limit']) <= 0.02)
                    ]
                    
                    # 2. åŸºäºæ¶¨è·Œå¹…çš„è¡¥å……åˆ¤æ–­ï¼ˆç§‘åˆ›æ¿ã€åˆ›ä¸šæ¿æ³¨å†Œåˆ¶è‚¡ç¥¨å¯èƒ½æœ‰ä¸åŒæ¶¨è·Œå¹…é™åˆ¶ï¼‰
                    pct_limit_up = market_data[
                        (market_data['pct_chg'] >= 9.8) &
                        (~market_data['ts_code'].isin(price_limit_up['ts_code']))
                    ]
                    
                    pct_limit_down = market_data[
                        (market_data['pct_chg'] <= -9.8) &
                        (~market_data['ts_code'].isin(price_limit_down['ts_code']))
                    ]
                    
                    # 3. åˆå¹¶ä¸¤ç§æ–¹å¼çš„ç»“æœ
                    limit_up_count = len(price_limit_up) + len(pct_limit_up)
                    limit_down_count = len(price_limit_down) + len(pct_limit_down)
                    
                    logger.info(f"ğŸ” æ¶¨åœè·Œåœè¯¦æƒ…: ä»·æ ¼åŒ¹é…æ¶¨åœ{len(price_limit_up)}åª+æ¶¨å¹…æ¶¨åœ{len(pct_limit_up)}åª, ä»·æ ¼åŒ¹é…è·Œåœ{len(price_limit_down)}åª+è·Œå¹…è·Œåœ{len(pct_limit_down)}åª")
                else:
                    # å¦‚æœæ²¡æœ‰æ¶¨è·Œåœæ•°æ®ï¼Œä½¿ç”¨æ¶¨è·Œå¹…ä¼°ç®—ï¼ˆè°ƒæ•´é˜ˆå€¼æ›´è´´è¿‘å®é™…ï¼‰
                    limit_up_count = len(market_data[market_data['pct_chg'] >= 9.8])
                    limit_down_count = len(market_data[market_data['pct_chg'] <= -9.8])
                    logger.info(f"âš ï¸ ä½¿ç”¨æ¶¨è·Œå¹…ä¼°ç®—: æ¶¨åœ{limit_up_count}åª, è·Œåœ{limit_down_count}åª")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æ¶¨è·Œåœä»·æ ¼å¤±è´¥: {e}")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ¶¨è·Œå¹…ä¼°ç®—ï¼ˆè°ƒæ•´é˜ˆå€¼ï¼‰
                limit_up_count = len(market_data[market_data['pct_chg'] >= 9.8])
                limit_down_count = len(market_data[market_data['pct_chg'] <= -9.8])
                logger.info(f"ğŸ”„ å¤‡ç”¨æ–¹æ¡ˆç»Ÿè®¡: æ¶¨åœ{limit_up_count}åª, è·Œåœ{limit_down_count}åª")
            
            total_count = len(market_data)
            limit_up_ratio = round((limit_up_count / total_count) * 100, 2) if total_count > 0 else 0
            limit_down_ratio = round((limit_down_count / total_count) * 100, 2) if total_count > 0 else 0
            
            result = {
                'limit_up_count': limit_up_count,
                'limit_down_count': limit_down_count,
                'limit_up_ratio': limit_up_ratio,
                'limit_down_ratio': limit_down_ratio
            }
            
            logger.info(f"ğŸ”´ æ¶¨è·Œåœæƒ…å†µ: æ¶¨åœ{limit_up_count}åª({limit_up_ratio}%), è·Œåœ{limit_down_count}åª({limit_down_ratio}%)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ¶¨è·Œåœåˆ†æå¤±è´¥: {e}")
            return {'limit_up_count': 0, 'limit_down_count': 0}
    
    def analyze_volume_distribution(self, market_data: pd.DataFrame) -> List[Dict]:
        """åˆ†ææˆäº¤é‡åˆ†å¸ƒ"""
        try:
            if market_data.empty:
                return []
            
            # è®¡ç®—æˆäº¤é‡ç»Ÿè®¡
            volume_data = market_data[market_data['vol'] > 0]['vol']
            if volume_data.empty:
                return []
            
            # å®šä¹‰æˆäº¤é‡åŒºé—´ï¼ˆå•ä½ï¼šä¸‡æ‰‹ï¼‰
            volume_ranges = [
                {'name': 'å¾®é‡(0-1ä¸‡æ‰‹)', 'min': 0, 'max': 10000},
                {'name': 'å°é‡(1-5ä¸‡æ‰‹)', 'min': 10000, 'max': 50000},
                {'name': 'ä¸­é‡(5-20ä¸‡æ‰‹)', 'min': 50000, 'max': 200000},
                {'name': 'å¤§é‡(20-50ä¸‡æ‰‹)', 'min': 200000, 'max': 500000},
                {'name': 'å·¨é‡(50ä¸‡æ‰‹ä»¥ä¸Š)', 'min': 500000, 'max': float('inf')}
            ]
            
            distribution = []
            total_count = len(volume_data)
            
            for range_info in volume_ranges:
                count = len(volume_data[
                    (volume_data >= range_info['min']) & 
                    (volume_data < range_info['max'])
                ])
                
                percentage = round((count / total_count) * 100, 2) if total_count > 0 else 0
                
                distribution.append({
                    'range': range_info['name'],
                    'count': count,
                    'percentage': percentage
                })
            
            logger.info(f"ğŸ“Š æˆäº¤é‡åˆ†å¸ƒåˆ†æå®Œæˆ: {len(distribution)}ä¸ªåŒºé—´")
            return distribution
            
        except Exception as e:
            logger.error(f"âŒ æˆäº¤é‡åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
            return []
    
    def analyze_market_cap_distribution(self, market_data: pd.DataFrame) -> List[Dict]:
        """åˆ†æå¸‚å€¼åˆ†å¸ƒ"""
        try:
            if market_data.empty:
                return []
            
            # è·å–æœ‰å¸‚å€¼æ•°æ®çš„è‚¡ç¥¨
            cap_data = market_data[market_data['total_mv'] > 0]['total_mv']
            if cap_data.empty:
                return []
            
            # å®šä¹‰å¸‚å€¼åŒºé—´ï¼ˆå•ä½ï¼šäº¿å…ƒï¼‰
            cap_ranges = [
                {'name': 'å°ç›˜è‚¡(0-50äº¿)', 'min': 0, 'max': 500000},
                {'name': 'ä¸­å°ç›˜(50-200äº¿)', 'min': 500000, 'max': 2000000},
                {'name': 'ä¸­ç›˜è‚¡(200-500äº¿)', 'min': 2000000, 'max': 5000000},
                {'name': 'å¤§ç›˜è‚¡(500-1000äº¿)', 'min': 5000000, 'max': 10000000},
                {'name': 'è¶…å¤§ç›˜(1000äº¿ä»¥ä¸Š)', 'min': 10000000, 'max': float('inf')}
            ]
            
            distribution = []
            total_count = len(cap_data)
            
            for range_info in cap_ranges:
                count = len(cap_data[
                    (cap_data >= range_info['min']) & 
                    (cap_data < range_info['max'])
                ])
                
                percentage = round((count / total_count) * 100, 2) if total_count > 0 else 0
                
                distribution.append({
                    'range': range_info['name'],
                    'count': count,
                    'percentage': percentage
                })
            
            logger.info(f"ğŸ’° å¸‚å€¼åˆ†å¸ƒåˆ†æå®Œæˆ: {len(distribution)}ä¸ªåŒºé—´")
            return distribution
            
        except Exception as e:
            logger.error(f"âŒ å¸‚å€¼åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
            return []
    
    def calculate_market_activity(self, market_data: pd.DataFrame) -> Dict:
        """è®¡ç®—å¸‚åœºæ´»è·ƒåº¦æŒ‡æ ‡"""
        try:
            if market_data.empty:
                return {}
            
            total_count = len(market_data)
            
            # æ´»è·ƒè‚¡ç¥¨ï¼ˆæˆäº¤é‡>0ï¼‰
            active_stocks = len(market_data[market_data['vol'] > 0])
            active_ratio = round((active_stocks / total_count) * 100, 2) if total_count > 0 else 0
            
            # é«˜æ¢æ‰‹ç‡è‚¡ç¥¨ï¼ˆ>5%ï¼‰
            high_turnover = len(market_data[market_data['turnover_rate'] > 5])
            high_turnover_ratio = round((high_turnover / total_count) * 100, 2) if total_count > 0 else 0
            
            # æ”¾é‡è‚¡ç¥¨ï¼ˆé‡æ¯”>2ï¼‰
            volume_surge = len(market_data[market_data['volume_ratio'] > 2])
            volume_surge_ratio = round((volume_surge / total_count) * 100, 2) if total_count > 0 else 0
            
            # å¹³å‡æ¢æ‰‹ç‡
            avg_turnover = round(market_data['turnover_rate'].mean(), 2) if not market_data['turnover_rate'].isna().all() else 0
            
            # å¹³å‡é‡æ¯”
            avg_volume_ratio = round(market_data['volume_ratio'].mean(), 2) if not market_data['volume_ratio'].isna().all() else 0
            
            result = {
                'active_stocks': active_stocks,
                'active_ratio': active_ratio,
                'high_turnover_stocks': high_turnover,
                'high_turnover_ratio': high_turnover_ratio,
                'volume_surge_stocks': volume_surge,
                'volume_surge_ratio': volume_surge_ratio,
                'avg_turnover_rate': avg_turnover,
                'avg_volume_ratio': avg_volume_ratio
            }
            
            logger.info(f"ğŸ¯ å¸‚åœºæ´»è·ƒåº¦: æ´»è·ƒ{active_stocks}åª({active_ratio}%), é«˜æ¢æ‰‹{high_turnover}åª({high_turnover_ratio}%)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¸‚åœºæ´»è·ƒåº¦è®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def analyze_market_breadth(self, trade_date: str = None) -> Dict:
        """æ‰§è¡Œå®Œæ•´çš„å¸‚åœºå®½åº¦åˆ†æ"""
        try:
            if not trade_date:
                trade_date = self.get_trading_date()
            
            logger.info(f"ğŸš€ å¼€å§‹å¸‚åœºå®½åº¦åˆ†æ ({trade_date})")
            
            # è·å–å¸‚åœºæ•°æ®
            market_data = self.get_market_daily_data(trade_date)
            if market_data.empty:
                raise Exception("æ— æ³•è·å–å¸‚åœºæ•°æ®")
            
            # æ‰§è¡Œå„é¡¹åˆ†æ
            logger.info("ğŸ“Š åˆ†ææ¶¨è·Œå®¶æ•°...")
            up_down_analysis = self.analyze_up_down_counts(market_data)
            
            logger.info("ğŸ“ˆ åˆ†ææ¶¨è·Œå¹…åˆ†å¸ƒ...")
            price_change_distribution = self.analyze_price_change_distribution(market_data)
            
            logger.info("ğŸ”´ åˆ†ææ¶¨åœè·Œåœ...")
            limit_analysis = self.analyze_limit_up_down(market_data, trade_date)
            
            logger.info("ğŸ“Š åˆ†ææˆäº¤é‡åˆ†å¸ƒ...")
            volume_distribution = self.analyze_volume_distribution(market_data)
            
            logger.info("ğŸ’° åˆ†æå¸‚å€¼åˆ†å¸ƒ...")
            market_cap_distribution = self.analyze_market_cap_distribution(market_data)
            
            logger.info("ğŸ¯ è®¡ç®—å¸‚åœºæ´»è·ƒåº¦...")
            market_activity = self.calculate_market_activity(market_data)
            
            # ç»¼åˆåˆ†æ
            result = {
                'success': True,
                'data': {
                    'trade_date': trade_date,
                    'up_down_analysis': up_down_analysis,
                    'price_change_distribution': price_change_distribution,
                    'limit_analysis': limit_analysis,
                    'volume_distribution': volume_distribution,
                    'market_cap_distribution': market_cap_distribution,
                    'market_activity': market_activity,
                    'data_source': 'TuShare Proæ·±åº¦API + AkShare (100%çœŸå®æ•°æ®)',
                    'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'data_quality': 'çœŸå®å®æ—¶å¯é ',
                    'total_stocks': len(market_data)
                }
            }
            
            logger.info("âœ… å¸‚åœºå®½åº¦åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¸‚åœºå®½åº¦åˆ†æå¤±è´¥: {e}")
            return {
                'success': False,
                'message': str(e),
                'data': None
            }

# å…¨å±€åˆ†æå™¨å®ä¾‹
analyzer = MarketBreadthAnalyzer()

def get_market_breadth_analysis(trade_date: str = None) -> Dict:
    """è·å–å¸‚åœºå®½åº¦åˆ†æç»“æœ"""
    return analyzer.analyze_market_breadth(trade_date)

if __name__ == "__main__":
    # æµ‹è¯•åˆ†æå™¨
    result = get_market_breadth_analysis()
    print(json.dumps(result, indent=2, ensure_ascii=False))